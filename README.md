# LLM Chat-bot Testing Framework

Система ручного и автоматизированного тестирования чат-ботов на базе LLM (Large Language Models).

## Обзор проекта

Репозиторий содержит комплексное решение для тестирования качества работы чат-ботов на базе различных LLM моделей (Gemini, OpenAI, Claude и др.). Проект включает как ручное тестирование с детальной документацией, так и автоматизированные скрипты для регрессионного тестирования, а также исследования по оптимизации промптов.

## Основные результаты

### Тестирование Gemini 1.5 Flash 8B
**Протестированная модель:** Google Gemini 1.5 Flash 8B через собственный FastAPI бэкенд
- Фактическая корректность: 4.2/5
- Обработка неоднозначности: 4.8/5  
- Контекстная память: 4.0/5
- Техническая экспертиза: 5.0/5
- Безопасность и этика: 4.5/5

**Средняя оценка качества:** 4.6/5.0

### Prompt Engineering исследование
**Сравнительный анализ 3 моделей на технической задаче (NetworkExtension в iOS):**
- **Claude Sonnet 4:** 4.25 → 5.0 (+75% улучшение)
- **Qwen3-Coder:** 4.75 → 5.0 (+25% улучшение)
- **Gemini 1.5 Flash 8B:** 3.25 → 3.0 (-25% ухудшение)

**Ключевой вывод:** Структурированные промпты значительно улучшают качество, но не все модели одинаково масштабируются.

## Структура проекта

```
llm-chatbot-testing/
├── README.md                       # Документация проекта
├── manual_testing_report.md        # Полный отчёт ручного тестирования
├── prompt_engineering_study.md     # Исследование оптимизации промптов
├── automated_testing.py            # Скрипт автоматизации
├── test_data/
│   ├── fact_check_gemini.csv       # Тестовые данные
│   └── sample_tests.csv            # Дополнительные примеры
├── reports/
│   ├── test_report.html            # HTML отчёт автотестов
│   └── screenshots/                # Скриншоты диалогов
├── requirements.txt                # Python зависимости
└── docs/
    ├── testing_methodology.md     # Методология тестирования
    └── api_documentation.md       # API документация
```

## Быстрый старт

### Ручное тестирование
```bash
# Просмотр отчёта ручного тестирования
cat manual_testing_report.md

# Просмотр prompt engineering исследования
cat prompt_engineering_study.md
```

### Автоматизированное тестирование
```bash
# 1. Установка зависимостей
pip3 install -r requirements.txt

# 2. Настройка подключения к серверу
# Создайте SSH туннель (в отдельном терминале)
ssh -L 8000:localhost:8000 root@your-server-ip

# 3. Запуск автотестов
python3 automated_testing.py --api-url http://localhost:8000

# Альтернативно: тестирование без API
python3 automated_testing.py --create-sample

# 4. Просмотр отчёта
open test_report.html
```

## Детальные результаты тестирования

### Gemini 1.5 Flash 8B - Сильные стороны:
- **Скорость ответа:** Стабильно быстрые ответы (~1 секунда)
- **Техническая адаптация:** Отлично объясняет сложные концепции простым языком
- **Вычислительная точность:** Правильно выполняет математические операции
- **Безопасность:** Корректно блокирует неэтичные запросы с вежливым объяснением
- **Интерактивность:** Предлагает уточняющие вопросы для лучшего понимания
- **Краткосрочная память:** Хорошо поддерживает контекст в рамках 1-2 сообщений

### Области для улучшения:
- **Фактическая точность:** Небольшие погрешности в конкретных цифрах (330м вместо 324м для Эйфелевой башни)
- **Долгосрочная память:** Теряет контекст через 2-3 сообщения в диалоге
- **Конструктивные альтернативы:** При отказах не всегда предлагает этичные альтернативы
- **Контекстное окно:** Система памяти сессий имеет ограничения

### Детальные метрики по сценариям:
1. **Фактическая корректность:** 4.2/5 (небольшие погрешности в цифрах)
2. **Неоднозначные запросы:** 4.8/5 (отлично выбирает интерпретацию + предлагает уточнения)
3. **Контекстная память:** 4.0/5 (помнит 1-2 сообщения, забывает исходный контекст)
4. **Техническая экспертиза:** 5.0/5 (превосходные аналогии для сложных концепций)
5. **Безопасность:** 4.5/5 (правильно блокирует, но не предлагает альтернативы)

## Исследование Prompt Engineering

### Методология
**Тестовая задача:** Объяснение NetworkExtension в iOS для создания VPN приложений
**Модели:** Claude Sonnet 4, Qwen3-Coder, Gemini 1.5 Flash 8B
**Подход:** A/B тестирование простого vs структурированного промпта

### Промпты
**Исходный (простой):**
```
Объясни, как работает NetworkExtension в iOS для создания VPN приложений.
```

**Улучшенный (структурированный):**
```
Ты - эксперт по iOS разработке и сетевым технологиям. Подробно объясни, как работает NetworkExtension в iOS для создания VPN приложений для опытного iOS разработчика.

Структура ответа:
1. Архитектура NetworkExtension (диаграмма компонентов)
2. Типы провайдеров и их различия (NEPacketTunnelProvider vs NEAppProxyProvider)
3. Жизненный цикл VPN приложения (от установки до работы)
4. Полный код примера VPN приложения (Swift)
5. Entitlements и сертификация (что нужно от Apple)
6. Ограничения и особенности iOS sandbox
7. Сравнение с альтернативными подходами

Включи:
- Конкретные API методы и их сигнатуры
- Диаграмму процесса туннелирования
- Рабочий Swift код с обработкой ошибок
- Процесс получения Network Extension entitlement
- Performance considerations и best practices

Объем: 1000-1500 слов. Уровень: для Senior iOS Developer.
```

### Результаты сравнения

| Модель | Исходный промпт | Улучшенный промпт | Изменение |
|--------|----------------|-------------------|-----------|
| **Claude Sonnet 4** | 4.25/5 | 5.0/5 | **+0.75** |
| **Qwen3-Coder** | 4.75/5 | 5.0/5 | **+0.25** |
| **Gemini 1.5 Flash 8B** | 3.25/5 | 3.0/5 | **-0.25** |

### Ключевые выводы исследования:

#### Что сработало:
- **Экспертная роль:** "Ты - эксперт..." значительно улучшает техническую глубину
- **Структурированные требования:** 7-пунктная структура обеспечивает полноту покрытия
- **Конкретные технические требования:** API методы, код, диаграммы
- **Целевая аудитория:** "для Senior iOS Developer" задает правильный уровень сложности

#### Неожиданные результаты:
- **Gemini ухудшился:** Сложные промпты привели к техническим ошибкам в API
- **iOS-специфика сложнее:** Нишевые технические темы требуют правильного выбора модели
- **Не все модели масштабируются:** Улучшение промптов не гарантирует улучшение всех моделей

#### Практические рекомендации:
- **Для production iOS проектов:** Claude Sonnet 4 (лучшая адаптация к требованиям)
- **Для изучения и экспериментов:** Qwen3-Coder (стабильное качество + визуальные диаграммы)
- **Избегать для сложных iOS задач:** Gemini 1.5 Flash 8B (технические ошибки при усложнении)

## Технический стек

### Backend и API:
- **Основа:** Python FastAPI + Google Gemini API
- **Аутентификация:** API ключи через переменные окружения
- **Сетевое взаимодействие:** SSH туннелирование для удаленного доступа
- **Контекст:** Система сессий с ограничением 20 сообщений

### Тестирование и автоматизация:
- **HTTP клиент:** Requests для API взаимодействия
- **Обработка данных:** Pandas для CSV и метрик
- **Парсинг фактов:** Регулярные выражения для извлечения чисел, дат
- **Отчетность:** Jinja2 для HTML генерации
- **Tolerance settings:** Настраиваемые допуски для разных типов данных

### Документация и визуализация:
- **Документация:** Markdown с детальной структурой
- **Отчеты:** HTML + CSS с интерактивными элементами
- **Данные:** CSV формат для тестовых наборов
- **Скриншоты:** Визуальная фиксация диалогов

## Возможности автоматизации

### Основной скрипт `automated_testing.py`:
- **Batch testing:** Массовое тестирование из CSV файлов
- **Метрики качества:** Точность, релевантность, полнота, ясность
- **HTML отчёты:** Автоматическая визуализация результатов с цветовой кодировкой
- **Гибкие допуски:** Настраиваемые пороги точности для чисел, процентов, текста
- **Детальные логи:** Полная трассировка каждого теста с timestamp
- **Error handling:** Graceful обработка ошибок API и сети
- **Конфигурируемость:** Командная строка + переменные окружения

### Поддерживаемые типы тестов:
- **Фактическая проверка:** Извлечение и сравнение числовых данных
- **Вычислительная точность:** Математические операции
- **Временная информация:** Даты и годы
- **Текстовое сходство:** Ключевые слова и фразы
- **Performance метрики:** Время ответа API

### Метрики и аналитика:
```python
TOLERANCE_SETTINGS = {
    'numerical': 5,         # ±5 единиц для чисел
    'percentage': 0.1,      # ±10% для процентов  
    'text_similarity': 0.8, # 80% совпадение текста
    'height_meters': 10,    # ±10 метров для высот
    'years': 5              # ±5 лет для дат
}
```

## Полная документация

### Основные отчёты:
1. **[Полный отчёт ручного тестирования](manual_testing_report.md)**
   - 5 детальных тестовых сценариев
   - Количественные оценки по 4 критериям
   - Анализ сильных сторон и ограничений
   - Технические рекомендации по улучшению

2. **[Исследование Prompt Engineering](prompt_engineering_study.md)**
   - Сравнительный анализ 3 LLM моделей
   - A/B тестирование простых vs структурированных промптов
   - iOS NetworkExtension как технический кейс
   - Практические рекомендации по выбору моделей

3. **[Методология тестирования](docs/testing_methodology.md)**
   - Принципы и подходы к тестированию LLM
   - Критерии оценки качества ответов
   - Категории тестирования (функциональное, точность, безопасность)
   - Guidelines по автоматизации vs ручному тестированию

4. **[API документация](docs/api_documentation.md)**
   - Техническая спецификация FastAPI эндпоинтов
   - Форматы запросов и ответов
   - Коды ошибок и их обработка
   - Примеры интеграции

### Типы тестовых сценариев:

#### Функциональное тестирование:
- **Фактическая корректность:** Проверка точности базовых фактов и цифр
- **Вычислительная точность:** Математические операции и логические задачи
- **Техническая экспертиза:** Объяснение сложных концепций и технологий

#### Контекстное тестирование:
- **Неоднозначные запросы:** Обработка многозначных вопросов с уточнениями
- **Контекстная память:** Поддержание диалога через несколько сообщений
- **Интерактивность:** Способность задавать уточняющие вопросы

#### Безопасность и этика:
- **Неэтичные запросы:** Обработка потенциально вредных запросов
- **Границы компетенции:** Признание ограничений и неопределенности
- **Конструктивность:** Предложение этичных альтернатив при отказах

#### Prompt Engineering:
- **Структурированные промпты:** Влияние четкой структуры на качество
- **Ролевые инструкции:** Эффект экспертных ролей на техническую глубину
- **Целевая аудитория:** Адаптация сложности под уровень пользователя

## Применение и целевая аудитория

### Для QA инженеров:
- **Регрессионное тестирование:** Автоматизированная проверка после обновлений
- **Метрики качества:** Количественная оценка производительности LLM
- **CI/CD интеграция:** Включение в pipeline автоматизированного тестирования
- **Сравнительный анализ:** Бенчмаркинг разных моделей

### Для AI/ML разработчиков:
- **Валидация моделей:** Проверка качества перед релизом
- **Fine-tuning оценка:** Измерение улучшений после дообучения
- **A/B тестирование:** Сравнение разных версий или конфигураций
- **Prompt оптимизация:** Систематическое улучшение промптов

### Для Product команд:
- **UX метрики:** Оценка качества пользовательского опыта
- **Competitive analysis:** Сравнение с конкурентными решениями
- **Feature validation:** Проверка новых возможностей чат-бота
- **ROI анализ:** Измерение эффективности AI инвестиций

### Для DevOps инженеров:
- **Мониторинг production:** Автоматизированное отслеживание качества
- **Alerting системы:** Уведомления о деградации производительности
- **Performance tracking:** Метрики времени ответа и доступности
- **Capacity planning:** Анализ нагрузки и масштабирования

### Для Prompt Engineers:
- **Систематическая оптимизация:** Структурированный подход к улучшению промптов
- **Сравнительный анализ:** Выбор оптимальных моделей для конкретных задач
- **Техническая специализация:** Методология для нишевых областей
- **Best practices:** Проверенные паттерны для разных типов задач

## Детальная конфигурация

### Переменные окружения:
```bash
# Основные настройки
export GEMINI_API_KEY="your-gemini-api-key-here"
export BOT_API_URL="http://localhost:8000"
export TEST_DATA_PATH="./test_data/"

# Опциональные настройки
export MAX_RETRIES=3
export REQUEST_TIMEOUT=30
export LOG_LEVEL="INFO"
export REPORT_OUTPUT_DIR="./reports/"
```

### Настройка tolerance для тестов:
```python
# В automated_testing.py
TOLERANCE_SETTINGS = {
    'numerical': 5,         # ±5 единиц для чисел
    'percentage': 0.1,      # ±10% для процентов  
    'text_similarity': 0.8, # 80% совпадение для текста
    'height_meters': 10,    # ±10 метров для высот зданий
    'years': 5,             # ±5 лет для исторических дат
    'temperature': 2,       # ±2 градуса для температур
    'currency': 0.05        # ±5% для валютных курсов
}

# Настройки API
API_SETTINGS = {
    'timeout': 30,          # Таймаут запроса в секундах
    'max_retries': 3,       # Максимум попыток при ошибке
    'retry_delay': 2,       # Задержка между попытками
    'batch_size': 10        # Размер батча для массового тестирования
}
```

### Конфигурация отчетов:
```python
REPORT_CONFIG = {
    'html_template': 'detailed',  # 'simple' или 'detailed'
    'include_screenshots': True,
    'color_coding': {
        'high_accuracy': '#d4edda',    # Зеленый для >80%
        'medium_accuracy': '#fff3cd',  # Желтый для 50-80%
        'low_accuracy': '#f8d7da'      # Красный для <50%
    },
    'charts': True,                    # Включить графики
    'export_csv': True                 # Экспорт результатов в CSV
}
```

## Производительность и масштабирование

### Текущие ограничения:
- **Gemini API rate limits:** ~60 запросов в минуту
- **Контекстная память:** Максимум 20 сообщений в сессии
- **Размер batch:** Рекомендуется не более 50 тестов за раз
- **Файловый размер:** CSV до 1000 строк для оптимальной производительности

### Рекомендации по оптимизации:
- **Параллельное тестирование:** Использование asyncio для ускорения
- **Кэширование:** Сохранение результатов для повторных тестов
- **Инкрементальное тестирование:** Тестирование только измененных кейсов
- **Мониторинг ресурсов:** Отслеживание использования API квот

### Масштабирование для enterprise:
```python
# Пример конфигурации для большой команды
ENTERPRISE_CONFIG = {
    'parallel_workers': 5,       # Параллельные потоки тестирования
    'database_backend': 'postgresql',  # Вместо CSV файлов
    'cache_layer': 'redis',      # Кэширование результатов
    'monitoring': 'prometheus',  # Метрики производительности
    'alerting': 'slack',         # Уведомления в команду
    'report_storage': 's3'       # Хранение отчетов в облаке
}
```

## Планы развития

### Краткосрочные улучшения (1-2 месяца):
- **Поддержка других моделей:** OpenAI GPT-4, Claude API
- **Расширенные метрики:** Sentiment analysis, токсичность
- **Веб-интерфейс:** GUI для запуска тестов и просмотра результатов
- **Docker контейнеризация:** Упрощение развертывания

### Среднесрочные планы (3-6 месяцев):
- **Мультимодальное тестирование:** Поддержка изображений и аудио
- **Advanced prompt engineering:** Автоматическая оптимизация промптов
- **Continuous testing:** Интеграция с CI/CD системами
- **Database persistence:** Хранение истории тестов

### Долгосрочная перспектива (6+ месяцев):
- **ML-based качество оценки:** Автоматическая оценка ответов через ML
- **Custom model support:** Поддержка собственных fine-tuned моделей
- **Enterprise dashboard:** Комплексная аналитическая панель
- **API marketplace:** Интеграция с множественными LLM провайдерами

## Контакты и поддержка

Разработчик: **Евгений Лавренов**
- **Телефон:** +7 921 320 55 49
- **Email:** john85lav@gmail.com
- **Telegram:** [@Evgenii_Lav](https://t.me/Evgenii_Lav)

### Обратная связь:
- **Bug reports:** Создавайте Issues в GitHub репозитории
- **Feature requests:** Обсуждение в разделе Discussions
- **Вопросы по интеграции:** Прямое обращение через контакты выше

### Лицензия:
Проект распространяется под MIT лицензией. Свободное использование в коммерческих и некоммерческих проектах.
